import 'dart:convert';
import 'dart:io';
import 'package:permission_handler/permission_handler.dart';
import 'package:flutter_sound/flutter_sound.dart'; // Codec í¬í•¨ëœ íŒ¨í‚¤ì§€
import 'package:flutter/material.dart';
import 'package:flutter_sound/public/flutter_sound_recorder.dart';
import 'package:http/http.dart' as http;
import 'package:path_provider/path_provider.dart';
import 'feedback_loading_page.dart';
import 'feedback_detail_page.dart';
import 'feedback_result_page.dart';
// import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'dart:io';

// í•¨ìˆ˜ ì •ì˜
Future<void> getCacheFileSize(String filePath) async {
  final file = File(filePath);

  if (await file.exists()) {
    final length = await file.length();
    print('íŒŒì¼ í¬ê¸°: $length bytes');
  } else {
    print('íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
  }
}


class CallPage extends StatefulWidget {
  final String scenario;
  const CallPage({required this.scenario, super.key});

  //CallPage({required this.scenario});
  @override
  State<CallPage> createState() => _CallPageState();
}
class _CallPageState extends State<CallPage> {
  FlutterSoundPlayer player = FlutterSoundPlayer();
  @override
  void initState() {
    super.initState();
    initRecorder();
    requestMicrophonePermission();
    player.openPlayer(); // ğŸ§ í”Œë ˆì´ì–´ ì—´ê¸°
  }

  @override
  void dispose() {
    recorder.closeRecorder();
    player.closePlayer(); // ğŸ§ í”Œë ˆì´ì–´ ë‹«ê¸°
    super.dispose();
  }

  // ğŸ”½ ë…¹ìŒ ìƒíƒœ ë³€ìˆ˜ ë° ê²½ë¡œ ì •ì˜ (ë‚˜ì¤‘ì— ë…¹ìŒ ì‹œì‘/ì¢…ë£Œ êµ¬í˜„ ì‹œ í•„ìš”)
  bool isRecording = false;
  FlutterSoundRecorder recorder = FlutterSoundRecorder();
  late String audioPath;


  Future<void> requestMicrophonePermission() async {
    var status = await Permission.microphone.status;
    if (!status.isGranted) {
      await Permission.microphone.request();
    }
  }

  Future<void> playRecording() async {
    if (audioPath.isNotEmpty) {
      await player.startPlayer(fromURI: audioPath);
      print("â–¶ ì¬ìƒ ì‹œì‘: $audioPath");
    } else {
      print("âš  ë…¹ìŒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.");
    }
  }


  Future<void> initRecorder() async {
    await recorder.openRecorder();
    await recorder.setSubscriptionDuration(const Duration(milliseconds: 500));

    final status = await recorder.isEncoderSupported(Codec.aacADTS);
    if (!status) {
      print('AAC ì¸ì½”ë”© ë¯¸ì§€ì›');
    }
  }


  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.white,
      body: SafeArea(
        child: Column(
          children: [
            Image.asset(
              'assets/building.png',
              width: double.infinity,
              height: 220,
              fit: BoxFit.contain,
            ),
            SizedBox(height: 30),

            // ì²« ë§í’ì„ 
            Padding(
              padding: const EdgeInsets.symmetric(horizontal: 16.0),
              child: Row(
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  Image.asset('assets/call_image.png', width: 24),
                  SizedBox(width: 8),
                  Flexible(
                    child: Container(
                      padding: EdgeInsets.all(14),
                      decoration: BoxDecoration(
                        color: Colors.green.shade100,
                        borderRadius: BorderRadius.only(
                          topLeft: Radius.circular(12),
                          topRight: Radius.circular(12),
                          bottomRight: Radius.circular(12),
                          bottomLeft: Radius.circular(0),
                        ),
                      ),
                      child: Text(
                        '"í•™ê³¼ ì‚¬ë¬´ì‹¤ì— ì „í™”ë¥¼ ê±¸ì–´ ì¥í•™ê¸ˆì— ëŒ€í•´ ë¬¸ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤..."',
                        style: TextStyle(fontSize: 14),
                      ),
                    ),
                  ),
                ],
              ),
            ),

            SizedBox(height: 20),

            // ë‘ ë²ˆì§¸ ë§í’ì„ 
            Padding(
              padding: const EdgeInsets.symmetric(horizontal: 16.0),
              child: Row(
                mainAxisAlignment: MainAxisAlignment.end,
                crossAxisAlignment: CrossAxisAlignment.start,
                children: [
                  Flexible(
                    child: Container(
                      padding: EdgeInsets.all(12),
                      decoration: BoxDecoration(
                        color: Colors.green.shade50,
                        borderRadius: BorderRadius.only(
                          topLeft: Radius.circular(12),
                          topRight: Radius.circular(12),
                          bottomLeft: Radius.circular(12),
                          bottomRight: Radius.circular(0),
                        ),
                      ),
                      child: Text(
                        'í†µí™”ë¥¼ ë§ˆì¹˜ì‹¤ ì¤€ë¹„ê°€ ë˜ì…¨ë‹¤ë©´,\nâ€˜ì¢…ë£Œâ€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.',
                        style: TextStyle(fontSize: 13),
                      ),
                    ),
                  ),
                  SizedBox(width: 8),
                  Image.asset('assets/touch_image.png', width: 24),
                ],
              ),
            ),

            Spacer(),

            ElevatedButton.icon(
              onPressed: () async {
                await playRecording();
              },
              icon: Icon(Icons.play_arrow),
              label: Text("ë…¹ìŒ ì¬ìƒ"),
              style: ElevatedButton.styleFrom(
                backgroundColor: Colors.green,
                padding: EdgeInsets.symmetric(horizontal: 20, vertical: 12),
              ),
            ),


            // í•˜ë‹¨ ë²„íŠ¼
            Padding(
              padding: const EdgeInsets.symmetric(horizontal: 40.0, vertical: 24),
              child: Row(
                mainAxisAlignment: MainAxisAlignment.spaceAround,
                children: [
                  Icon(Icons.dialpad, size: 32, color: Colors.grey.shade600),
                  ElevatedButton(
                    onPressed: () async {
                      if (!isRecording) {
                        // ë…¹ìŒ ì‹œì‘
                        Directory tempDir = await getTemporaryDirectory();
                        audioPath = '${tempDir.path}/recorded_audio.wav';
                        await recorder.startRecorder(
                            toFile: audioPath,
                            codec: Codec.pcm16WAV, // âœ… ë³€ê²½: WAVë¡œ ì €ì¥
                            );
                        print("âœ… ë…¹ìŒ ì‹œì‘ë¨: $audioPath");
                      } else {
                        // ë…¹ìŒ ì¢…ë£Œ + ì„œë²„ ì „ì†¡
                        await recorder.stopRecorder();
                        print("ğŸ›‘ ë…¹ìŒ ì¢…ë£Œë¨");
                        print("ğŸ“ íŒŒì¼ ê²½ë¡œ: $audioPath");
                        getCacheFileSize(audioPath);

                        await sendToServer(File(audioPath));
                        await evalAudio("tester1");

                        Navigator.push(
                          context,
                          MaterialPageRoute(builder: (context) => const FeedbackResultPage()),
                        );
                      }
                      setState(() {
                        isRecording = !isRecording;
                      });
                    },
                    style: ElevatedButton.styleFrom(
                      backgroundColor: Colors.red,
                      shape: CircleBorder(),
                      padding: EdgeInsets.all(16),
                    ),
                    child: Icon(Icons.call_end, size: 28, color: Colors.white),
                  ),
                  Icon(Icons.volume_up, size: 32, color: Colors.grey.shade600),
                ],
              ),
            ),
          ],
        ),
      ),
    );
  }

  Future<void> sendToServer(File audioFile) async {
    var uri = Uri.parse('http://10.0.2.2:8000/chat/audio');
    var request = http.MultipartRequest('POST', uri)
      ..files.add(await http.MultipartFile.fromPath('file', audioFile.path))
      ..fields['user_id'] = 'tester1';  // âœ… ì—¬ê¸°ì— ì‚¬ìš©ì ID ë„£ê¸°

    var response = await request.send();

    if (response.statusCode == 200) {
      print("âœ… íŒŒì¼ ì „ì†¡ ì„±ê³µ");
      final responseBody = await response.stream.bytesToString();
      print("ğŸ§ ì‘ë‹µ ë°ì´í„°: $responseBody");
    } else {
      print("âŒ íŒŒì¼ ì „ì†¡ ì‹¤íŒ¨: ${response.statusCode}");
    }
  }

  Future<void> evalAudio(String userId) async {
    var uri = Uri.parse("http://10.0.2.2:8000/evaluate-audio/?userId=$userId");

    try {
      var response = await http.get(uri); // íŒŒì¼ ì—†ìŒ â†’ GET ìš”ì²­ ê°€ëŠ¥

      if (response.statusCode == 200) {
        var result = jsonDecode(response.body);
        print("âœ… í‰ê°€ ê²°ê³¼: $result");

        // ê²°ê³¼ ì „ë‹¬ or í™”ë©´ ì´ë™
      } else {
        print("âŒ ì„œë²„ ì˜¤ë¥˜: ${response.statusCode}");
      }
    } catch (e) {
      print("âŒ ìš”ì²­ ì‹¤íŒ¨: $e");
    }
  }
}


